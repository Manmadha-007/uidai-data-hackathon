{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afced23b",
   "metadata": {},
   "source": [
    "# Demographic Update Dataset – Data Concatenation and Cleaning\n",
    "\n",
    "## Overview\n",
    "This notebook focuses on preparing the Aadhaar **Demographic Update Dataset** for downstream analysis as part of the UIDAI Data Hackathon.\n",
    "\n",
    "The demographic update data has been provided as multiple CSV files, each representing a partition of the same logical dataset.\n",
    "Before analysis, these files must be combined, validated, and cleaned in a consistent and reproducible manner.\n",
    "\n",
    "## Objectives\n",
    "The objectives of this notebook are to:\n",
    "\n",
    "1. Load and inventory all demographic update data files\n",
    "2. Validate schema consistency across file partitions\n",
    "3. Concatenate the files into a unified dataset\n",
    "4. Perform minimal and justified data cleaning, including:\n",
    "   - Date parsing (if applicable)\n",
    "   - Validation of demographic update fields\n",
    "   - Standardization of geographic attributes\n",
    "5. Persist a clean demographic update dataset for analysis\n",
    "\n",
    "## Scope and Design Principles\n",
    "- This notebook is strictly limited to data preparation\n",
    "- No exploratory or inferential analysis is performed here\n",
    "- Cleaning actions are evidence-driven and fully documented\n",
    "- Administrative semantics are preserved unless explicitly justified\n",
    "\n",
    "## Output\n",
    "The final output of this notebook is:\n",
    "\n",
    "[03_Processed_Data/demographic_update_clean.csv](..\\03_Processed_Data\\demographic_update_clean.csv)\n",
    "\n",
    "This dataset will be used in downstream analytical notebooks.\n",
    "\n",
    "## Reproducibility\n",
    "All steps in this notebook are deterministic and can be rerun end-to-end using the raw source files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb7fc6",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Library Imports\n",
    "\n",
    "This step initializes the Python environment and imports the required libraries to ensure consistent data handling and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee66cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b0861a",
   "metadata": {},
   "source": [
    "## Step 2: Defining the Demographic Update Data Source and File Inventory\n",
    "\n",
    "The demographic update dataset is provided as multiple CSV files.\n",
    "This step identifies all available files and verifies that the expected number of partitions is present before loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14b9acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../01_Raw_Data_National/demographic_update/api_data_aadhar_demographic_0_500000.csv'),\n",
       " WindowsPath('../01_Raw_Data_National/demographic_update/api_data_aadhar_demographic_1000000_1500000.csv'),\n",
       " WindowsPath('../01_Raw_Data_National/demographic_update/api_data_aadhar_demographic_1500000_2000000.csv'),\n",
       " WindowsPath('../01_Raw_Data_National/demographic_update/api_data_aadhar_demographic_2000000_2071700.csv'),\n",
       " WindowsPath('../01_Raw_Data_National/demographic_update/api_data_aadhar_demographic_500000_1000000.csv')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to raw demographic update data\n",
    "DEMOGRAPHIC_DATA_PATH = Path(\"../01_Raw_Data_National/demographic_update\")\n",
    "\n",
    "# List all demographic update CSV files\n",
    "demographic_files = sorted(DEMOGRAPHIC_DATA_PATH.glob(\"*.csv\"))\n",
    "\n",
    "demographic_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56deae3e",
   "metadata": {},
   "source": [
    "## Step 3: Loading Demographic Update Data with Provenance Tracking\n",
    "\n",
    "In this step, each demographic update CSV file is loaded into memory.\n",
    "A temporary provenance column is added to track the source file for each record, enabling validation of successful ingestion and concatenation.\n",
    "\n",
    "This column is used only during data preparation and is removed before persisting the final dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63c778f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load demographic update files with provenance tracking\n",
    "demographic_dfs = []\n",
    "\n",
    "for file_path in demographic_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"source_file\"] = file_path.name\n",
    "    demographic_dfs.append(df)\n",
    "\n",
    "# Confirm all files are loaded\n",
    "len(demographic_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94092ad5",
   "metadata": {},
   "source": [
    "## Step 4: Schema Validation Across Demographic Update Files\n",
    "\n",
    "Before concatenating the demographic update files, it is essential to confirm that all partitions share a consistent schema.\n",
    "Schema validation ensures that each column represents the same attribute across all files and prevents silent data corruption during concatenation.\n",
    "\n",
    "This step compares column names, column counts, and column ordering across all demographic update files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "267ecf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for file 1:\n",
      "['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_', 'source_file']\n",
      "--------------------------------------------------------------------------------\n",
      "Schema for file 2:\n",
      "['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_', 'source_file']\n",
      "--------------------------------------------------------------------------------\n",
      "Schema for file 3:\n",
      "['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_', 'source_file']\n",
      "--------------------------------------------------------------------------------\n",
      "Schema for file 4:\n",
      "['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_', 'source_file']\n",
      "--------------------------------------------------------------------------------\n",
      "Schema for file 5:\n",
      "['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_', 'source_file']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract column schemas from each demographic update DataFrame\n",
    "schemas = [df.columns.tolist() for df in demographic_dfs]\n",
    "\n",
    "# Display schemas for comparison\n",
    "for idx, schema in enumerate(schemas, start=1):\n",
    "    print(f\"Schema for file {idx}:\")\n",
    "    print(schema)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Check whether all schemas are identical\n",
    "all_schemas_identical = all(schema == schemas[0] for schema in schemas)\n",
    "all_schemas_identical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57a8c4",
   "metadata": {},
   "source": [
    "## Step 5: Concatenating the Demographic Update Dataset\n",
    "\n",
    "After confirming schema consistency across all demographic update files, the individual partitions are concatenated into a single unified dataset.\n",
    "This step combines all records while preserving row-level integrity and prepares the data for subsequent validation and cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b1a9023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2071700, 7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all demographic update DataFrames\n",
    "demographic_combined = pd.concat(demographic_dfs, ignore_index=True)\n",
    "\n",
    "# Inspect the shape of the combined dataset\n",
    "demographic_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfb1812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_file\n",
       "api_data_aadhar_demographic_0_500000.csv           500000\n",
       "api_data_aadhar_demographic_1000000_1500000.csv    500000\n",
       "api_data_aadhar_demographic_1500000_2000000.csv    500000\n",
       "api_data_aadhar_demographic_500000_1000000.csv     500000\n",
       "api_data_aadhar_demographic_2000000_2071700.csv     71700\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_combined[\"source_file\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998294c",
   "metadata": {},
   "source": [
    "## Step 6: Initial Data Quality Assessment and Cleaning Strategy\n",
    "\n",
    "Before applying any cleaning operations, an initial assessment of the demographic update dataset is performed.\n",
    "This step focuses on understanding data completeness, data types, and potential structural issues that may affect downstream analysis.\n",
    "\n",
    "The objective is to identify:\n",
    "- Columns with missing or inconsistent values\n",
    "- Data types that require conversion (e.g., dates)\n",
    "- Fields that may require standardization (e.g., geographic attributes)\n",
    "\n",
    "All cleaning decisions applied in subsequent steps are driven by observations made here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d21ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2071700 entries, 0 to 2071699\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   date           object\n",
      " 1   state          object\n",
      " 2   district       object\n",
      " 3   pincode        int64 \n",
      " 4   demo_age_5_17  int64 \n",
      " 5   demo_age_17_   int64 \n",
      " 6   source_file    object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 110.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# High-level overview of the demographic update dataset\n",
    "demographic_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9bb7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "state            0\n",
       "district         0\n",
       "pincode          0\n",
       "demo_age_5_17    0\n",
       "demo_age_17_     0\n",
       "source_file      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc38bc",
   "metadata": {},
   "source": [
    "## Step 7: Applying Minimal and Justified Data Cleaning (Demographic Update)\n",
    "\n",
    "Based on the data quality assessment, the demographic update dataset is complete and structurally consistent.\n",
    "Cleaning actions in this step are intentionally minimal and focused on correctness and consistency, without introducing analytical assumptions.\n",
    "\n",
    "The operations performed include:\n",
    "- Robust parsing of the date column\n",
    "- Validation of demographic age-count fields\n",
    "- Standardization of State names using the canonical mapping adopted in Enrollment\n",
    "- Structural standardization of District names (formatting only)\n",
    "- Removal of temporary ingestion-related columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1f049",
   "metadata": {},
   "source": [
    "### Step 7A: Robust Date Parsing\n",
    "\n",
    "The demographic update dataset contains date values stored as text and expressed in more than one valid format,\n",
    "which is common in administrative datasets collected across different reporting systems.\n",
    "\n",
    "To ensure reliable temporal analysis and avoid data loss, a robust date parsing strategy is applied that:\n",
    "- Explicitly handles all observed date formats\n",
    "- Respects the day-first convention used in Indian datasets\n",
    "- Preserves all records without arbitrary deletion\n",
    "\n",
    "Date parsing is performed deterministically, and all parsed values are validated before proceeding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b45665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Work on a clean copy\n",
    "demographic_clean = demographic_combined.copy()\n",
    "\n",
    "# Attempt 1: DD-MM-YYYY\n",
    "parsed_dash = pd.to_datetime(\n",
    "    demographic_clean[\"date\"],\n",
    "    format=\"%d-%m-%Y\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Attempt 2: D/M/YYYY (Indian day-first)\n",
    "parsed_slash = pd.to_datetime(\n",
    "    demographic_clean[\"date\"],\n",
    "    dayfirst=True,\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Combine parsing attempts\n",
    "demographic_clean[\"date\"] = parsed_dash.fillna(parsed_slash)\n",
    "\n",
    "# Validate parsing\n",
    "demographic_clean[\"date\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4842b05",
   "metadata": {},
   "source": [
    "### Step 7B: Validation of Demographic Age Fields\n",
    "\n",
    "Demographic update records include age-segmented counts.\n",
    "These fields are validated to ensure basic numerical integrity prior to analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d38a277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_age_5_17    0\n",
       "demo_age_17_     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_cols = [\"demo_age_5_17\", \"demo_age_17_\"]\n",
    "\n",
    "# Check for negative values\n",
    "(demographic_clean[age_cols] < 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103f4c8",
   "metadata": {},
   "source": [
    "### Step 7C: Standardization of State Names\n",
    "\n",
    "To ensure consistency across datasets, State values are normalized using the same canonical mapping\n",
    "applied to the Enrollment dataset. This enables reliable cross-dataset aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75ea8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize State column\n",
    "for col in [\"state\"]:\n",
    "    demographic_clean[col] = (\n",
    "        demographic_clean[col]\n",
    "        .astype(str)\n",
    "        .str.strip()          # remove leading/trailing whitespace\n",
    "        .str.title()          # standardize casing (e.g., 'karnataka' -> 'Karnataka')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22f7100a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of unique states\n",
    "demographic_clean[\"state\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a430e170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Uttar Pradesh', 'Andhra Pradesh', 'Gujarat', 'Rajasthan',\n",
       "       'Karnataka', 'West Bengal', 'Telangana', 'Odisha', 'Maharashtra',\n",
       "       'Kerala', 'Bihar', 'Tamil Nadu', 'Madhya Pradesh', 'Assam',\n",
       "       'Tripura', 'Arunachal Pradesh', 'Punjab', 'Jharkhand', 'Delhi',\n",
       "       'Chandigarh', 'Chhattisgarh', 'Jammu And Kashmir', 'Mizoram',\n",
       "       'Nagaland', 'Himachal Pradesh', 'Goa', 'Haryana', 'Meghalaya',\n",
       "       'Uttarakhand', 'Manipur', 'Daman And Diu', 'Puducherry', 'Sikkim',\n",
       "       'Ladakh', 'Dadra And Nagar Haveli And Daman And Diu',\n",
       "       'Dadra And Nagar Haveli', 'Orissa', 'Pondicherry',\n",
       "       'Andaman & Nicobar Islands', 'Andaman And Nicobar Islands',\n",
       "       'Daman & Diu', 'West  Bengal', 'Jammu & Kashmir', 'Lakshadweep',\n",
       "       'Dadra & Nagar Haveli', 'Westbengal', 'West Bangal', 'Chhatisgarh',\n",
       "       'West Bengli', 'Darbhanga', 'Puttenahalli', 'Uttaranchal',\n",
       "       'Balanagar', 'Jaipur', 'Madanapalle', '100000', 'Nagpur',\n",
       "       'Raja Annamalai Puram'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_clean[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "905c2380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Canonical state name mapping\n",
    "state_normalization_map = {\n",
    "    # West Bengal variants\n",
    "    \"West Bengal\": \"West Bengal\",\n",
    "    \"West  Bengal\": \"West Bengal\",\n",
    "    \"West Bangal\": \"West Bengal\",\n",
    "    \"Westbengal\": \"West Bengal\",\n",
    "\n",
    "    # Odisha / Orissa\n",
    "    \"Orissa\": \"Odisha\",\n",
    "\n",
    "    # Jammu & Kashmir\n",
    "    \"Jammu & Kashmir\": \"Jammu And Kashmir\",\n",
    "\n",
    "    # Andaman & Nicobar\n",
    "    \"Andaman & Nicobar Islands\": \"Andaman And Nicobar Islands\",\n",
    "\n",
    "    # UT merger\n",
    "    \"Dadra & Nagar Haveli\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Daman & Diu\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Daman And Diu\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Dadra And Nagar Haveli\": \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"The Dadra And Nagar Haveli And Daman And Diu\":\n",
    "        \"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "\n",
    "    # Puducherry\n",
    "    \"Pondicherry\": \"Puducherry\",\n",
    "\n",
    "    \"Tamilnadu\": \"Tamil Nadu\",\n",
    "    \"West Bengli\": \"West Bengal\",\n",
    "    \"Chhatisgarh\": \"Chhattisgarh\",\n",
    "    \"Uttaranchal\": \"Uttarakhand\"\n",
    "}\n",
    "\n",
    "LOCALITY_TO_STATE = {\n",
    "    \"Nagpur\": \"Maharashtra\",                # Nagpur city / district is in Maharashtra. :contentReference[oaicite:2]{index=2}\n",
    "    \"Darbhanga\": \"Bihar\",                  # Darbhanga district in Bihar. :contentReference[oaicite:3]{index=3}\n",
    "    \"Jaipur\": \"Rajasthan\",                 # Jaipur city / district in Rajasthan. :contentReference[oaicite:4]{index=4}\n",
    "    \"Balanagar\": \"Telangana\",              # Balanagar (Hyderabad neighbourhood) in Telangana. :contentReference[oaicite:5]{index=5}\n",
    "    \"Puttenahalli\": \"Karnataka\",           # Puttenahalli (Bengaluru suburb) in Karnataka. :contentReference[oaicite:6]{index=6}\n",
    "    \"Raja Annamalai Puram\": \"Tamil Nadu\",  # R.A. Puram (Chennai neighbourhood) in Tamil Nadu. :contentReference[oaicite:7]{index=7}\n",
    "    \"Madanapalle\": \"Andhra Pradesh\"        # Madanapalle is a town in Andhra Pradesh. (common knowledge / can be verified)\n",
    "}\n",
    "\n",
    "demographic_clean[\"state\"] = (\n",
    "    demographic_clean[\"state\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    "    .replace(state_normalization_map)\n",
    ")\n",
    "\n",
    "# if state value is one of the localities, map to parent state\n",
    "demographic_clean[\"state\"] = (\n",
    "    demographic_clean[\"state\"]\n",
    "    .replace(LOCALITY_TO_STATE)\n",
    ")\n",
    "\n",
    "official_states = [\n",
    "    \"Andhra Pradesh\",\"Arunachal Pradesh\",\"Assam\",\"Bihar\",\"Chhattisgarh\",\"Goa\",\"Gujarat\",\n",
    "    \"Haryana\",\"Himachal Pradesh\",\"Jharkhand\",\"Karnataka\",\"Kerala\",\"Madhya Pradesh\",\n",
    "    \"Maharashtra\",\"Manipur\",\"Meghalaya\",\"Mizoram\",\"Nagaland\",\"Odisha\",\"Punjab\",\"Rajasthan\",\n",
    "    \"Sikkim\",\"Tamil Nadu\",\"Telangana\",\"Tripura\",\"Uttar Pradesh\",\"Uttarakhand\",\"West Bengal\",\n",
    "    \"Andaman And Nicobar Islands\",\"Chandigarh\",\"Dadra And Nagar Haveli And Daman And Diu\",\n",
    "    \"Delhi\",\"Jammu And Kashmir\",\"Ladakh\",\"Lakshadweep\",\"Puducherry\"\n",
    "]\n",
    "\n",
    "demographic_clean = demographic_clean[\n",
    "    demographic_clean[\"state\"].isin(official_states)\n",
    "].copy()\n",
    "\n",
    "demographic_clean['state'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d8a64de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Uttar Pradesh', 'Andhra Pradesh', 'Gujarat', 'Rajasthan',\n",
       "       'Karnataka', 'West Bengal', 'Telangana', 'Odisha', 'Maharashtra',\n",
       "       'Kerala', 'Bihar', 'Tamil Nadu', 'Madhya Pradesh', 'Assam',\n",
       "       'Tripura', 'Arunachal Pradesh', 'Punjab', 'Jharkhand', 'Delhi',\n",
       "       'Chandigarh', 'Chhattisgarh', 'Jammu And Kashmir', 'Mizoram',\n",
       "       'Nagaland', 'Himachal Pradesh', 'Goa', 'Haryana', 'Meghalaya',\n",
       "       'Uttarakhand', 'Manipur',\n",
       "       'Dadra And Nagar Haveli And Daman And Diu', 'Puducherry', 'Sikkim',\n",
       "       'Ladakh', 'Andaman And Nicobar Islands', 'Lakshadweep'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_clean[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f70aed",
   "metadata": {},
   "source": [
    "### Step 7D: Structural Standardization of District Names\n",
    "\n",
    "District names are standardized structurally to remove formatting noise while preserving\n",
    "original administrative semantics. No semantic remapping or merging is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "484470ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_clean[\"district\"] = (\n",
    "    demographic_clean[\"district\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.replace(r\"\\*\", \"\", regex=True)\n",
    "    .str.replace(r\"[()]\", \"\", regex=True)\n",
    "    .str.replace(\"–\", \"-\", regex=False)\n",
    "    .str.replace(\"−\", \"-\", regex=False)\n",
    "    .str.replace(\"?\", \"\", regex=False)\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "# Remove clearly invalid direction-only tokens\n",
    "invalid_districts = {\"East\", \"West\", \"North\", \"South\", \"North East\"}\n",
    "demographic_clean = demographic_clean[\n",
    "    ~demographic_clean[\"district\"].isin(invalid_districts)\n",
    "]\n",
    "\n",
    "demographic_clean[\"district\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07fa947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop temporary provenance column\n",
    "if \"source_file\" in demographic_clean.columns:\n",
    "    demographic_clean = demographic_clean.drop(columns=[\"source_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d63ebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2069863 entries, 0 to 2071699\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   date           datetime64[ns]\n",
      " 1   state          object        \n",
      " 2   district       object        \n",
      " 3   pincode        int64         \n",
      " 4   demo_age_5_17  int64         \n",
      " 5   demo_age_17_   int64         \n",
      "dtypes: datetime64[ns](1), int64(3), object(2)\n",
      "memory usage: 110.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Gorakhpur</td>\n",
       "      <td>273213</td>\n",
       "      <td>49</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Chittoor</td>\n",
       "      <td>517132</td>\n",
       "      <td>22</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>360006</td>\n",
       "      <td>65</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Srikakulam</td>\n",
       "      <td>532484</td>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>Udaipur</td>\n",
       "      <td>313801</td>\n",
       "      <td>45</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date           state    district  pincode  demo_age_5_17  demo_age_17_\n",
       "0 2025-03-01   Uttar Pradesh   Gorakhpur   273213             49           529\n",
       "1 2025-03-01  Andhra Pradesh    Chittoor   517132             22           375\n",
       "2 2025-03-01         Gujarat      Rajkot   360006             65           765\n",
       "3 2025-03-01  Andhra Pradesh  Srikakulam   532484             24           314\n",
       "4 2025-03-01       Rajasthan     Udaipur   313801             45           785"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_clean.info()\n",
    "demographic_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126d15b",
   "metadata": {},
   "source": [
    "### Step 7 Summary\n",
    "\n",
    "The demographic update dataset now satisfies the following:\n",
    "- Dates are consistently parsed and temporally reliable\n",
    "- Age-count fields are validated for numerical integrity\n",
    "- State names are canonical and consistent with Enrollment\n",
    "- District names are structurally clean while preserving semantics\n",
    "- Temporary ingestion artifacts are removed\n",
    "\n",
    "The dataset is ready to be persisted for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e358b8b",
   "metadata": {},
   "source": [
    "## Step 8: Persisting the Clean Demographic Update Dataset\n",
    "\n",
    "After completing all validation and cleaning steps, the demographic update dataset is finalized.\n",
    "In this step, the cleaned dataset is persisted to disk to serve as the single source of truth\n",
    "for all downstream analytical tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0315a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../03_Processed_Data/demographic_update_clean.csv')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define output directory\n",
    "OUTPUT_DIR = Path(\"../03_Processed_Data\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Save cleaned demographic update dataset\n",
    "output_path = OUTPUT_DIR / \"demographic_update_clean.csv\"\n",
    "demographic_clean.to_csv(output_path, index=False)\n",
    "\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6722179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Gorakhpur</td>\n",
       "      <td>273213</td>\n",
       "      <td>49</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Chittoor</td>\n",
       "      <td>517132</td>\n",
       "      <td>22</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>360006</td>\n",
       "      <td>65</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Srikakulam</td>\n",
       "      <td>532484</td>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>Udaipur</td>\n",
       "      <td>313801</td>\n",
       "      <td>45</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           state    district  pincode  demo_age_5_17  demo_age_17_\n",
       "0  2025-03-01   Uttar Pradesh   Gorakhpur   273213             49           529\n",
       "1  2025-03-01  Andhra Pradesh    Chittoor   517132             22           375\n",
       "2  2025-03-01         Gujarat      Rajkot   360006             65           765\n",
       "3  2025-03-01  Andhra Pradesh  Srikakulam   532484             24           314\n",
       "4  2025-03-01       Rajasthan     Udaipur   313801             45           785"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick verification of saved file\n",
    "pd.read_csv(output_path, nrows=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
